{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "import os\r\n",
    "import math\r\n",
    "import pickle\r\n",
    "import random\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from kaggle import KaggleApi\r\n",
    "\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "\r\n",
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.simplefilter('ignore')\r\n",
    "\r\n",
    "\r\n",
    "def print_div(fold):\r\n",
    "    title = f\" fold {fold} \"\r\n",
    "    eq = \"=\" * (int((40 - len(title)) / 2))\r\n",
    "    str_title = eq + title + eq\r\n",
    "    print(\"=\" * len(str_title))\r\n",
    "    print(str_title)\r\n",
    "    print(\"=\" * len(str_title))\r\n",
    "\r\n",
    "\r\n",
    "def kaggle_authentication():\r\n",
    "    api = KaggleApi()\r\n",
    "    api.authenticate()\r\n",
    "    return api\r\n",
    "\r\n",
    "def download_dataset(api, competition, path):\r\n",
    "    api.competition_download_files(competition, path=None, force=False, quiet=False)\r\n",
    "\r\n",
    "def submit_predict(api, competition, fpath, message):\r\n",
    "    api.competition_submit(fpath, message, competition)\r\n",
    "\r\n",
    "def seed_everything(seed=42):\r\n",
    "    random.seed(seed)\r\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
    "    np.random.seed(seed)\r\n",
    "\r\n",
    "def save_model(model, fpath):\r\n",
    "    with open(fpath,'wb') as file:\r\n",
    "        file.write(pickle.dumps(model))\r\n",
    "\r\n",
    "def load_datasets(train_fpath, test_fpath, solution_fpath):\r\n",
    "    train = pd.read_csv(train_fpath)\r\n",
    "    test = pd.read_csv(test_fpath)\r\n",
    "    submission = pd.read_csv(solution_fpath)\r\n",
    "    return train, test, submission\r\n",
    "\r\n",
    "def get_row_statistics(train, test, features):\r\n",
    "    train['n_missing'] = train[features].isna().sum(axis=1)\r\n",
    "    test['n_missing'] = test[features].isna().sum(axis=1)\r\n",
    "    train['std'] = train[features].std(axis=1)\r\n",
    "    test['std'] = test[features].std(axis=1)\r\n",
    "    features += ['n_missing', 'std']\r\n",
    "    n_missing = train['n_missing'].copy()\r\n",
    "    return train, test, features, n_missing\r\n",
    "\r\n",
    "def fill_and_scale(train, test, features):\r\n",
    "    scaler = StandardScaler()\r\n",
    "    train[features] = train[features].fillna(train[features].mean())\r\n",
    "    test[features] = test[features].fillna(test[features].mean())\r\n",
    "    train[features] = scaler.fit_transform(train[features])\r\n",
    "    test[features] = scaler.transform(test[features])\r\n",
    "    return train, test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "api = kaggle_authentication()\r\n",
    "competition = 'tabular-playground-series-sep-2021'\r\n",
    "destination = '.'\r\n",
    "download_dataset(api, competition, '.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "api = kaggle_authentication()\r\n",
    "submit_file = 'xgb_submission.csv'\r\n",
    "message = 'Submit via python script'\r\n",
    "competition = 'tabular-playground-series-sep-2021'\r\n",
    "submit_predict(api, competition, submit_file, message)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "N_SPLITS = 5\r\n",
    "N_ESTIMATORS = 20000\r\n",
    "EARLY_STOPPING_ROUNDS = 200\r\n",
    "VERBOSE = 10\r\n",
    "SEED = 2021\r\n",
    "\r\n",
    "seed_everything(SEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "train_fpath = \"train.csv\"\r\n",
    "test_fpath = \"test.csv\"\r\n",
    "solution_fpath = \"sample_solution.csv\"\r\n",
    "train, test, submission = load_datasets(train_fpath, test_fpath, solution_fpath)\r\n",
    "\r\n",
    "features = [col for col in test.columns if 'f' in col]\r\n",
    "TARGET = 'claim'\r\n",
    "\r\n",
    "target = train[TARGET].copy()\r\n",
    "\r\n",
    "train, test, features, n_missing = get_row_statistics(train, test, features)\r\n",
    "train, test = fill_and_scale(train, test, features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "Xgb_params = {\r\n",
    "    'objective': 'binary:logistic',\r\n",
    "    'n_estimators': N_ESTIMATORS,\r\n",
    "    'learning_rate': 5e-3,\r\n",
    "    'min_split_loss': 0,\r\n",
    "    'max_depth': 6,\r\n",
    "    'min_child_weight': 256,\r\n",
    "    'max_delta_step': 0,\r\n",
    "    'subsample': 0.6,\r\n",
    "    'colsample_bytree': 0.4,\r\n",
    "    'reg_lambda': 1e-1,\r\n",
    "    'reg_alpha': 10.0\r\n",
    "}\r\n",
    "\r\n",
    "lgb_oof = np.zeros(train.shape[0])\r\n",
    "lgb_pred = np.zeros(test.shape[0])\r\n",
    "lgb_importances = pd.DataFrame()\r\n",
    "\r\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\r\n",
    "\r\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=n_missing)):\r\n",
    "    print_div(fold)\r\n",
    "\r\n",
    "    X_train = train[features].iloc[trn_idx]\r\n",
    "    y_train = target.iloc[trn_idx]\r\n",
    "    X_valid = train[features].iloc[val_idx]\r\n",
    "    y_valid = target.iloc[val_idx]\r\n",
    "    X_test = test[features]\r\n",
    "\r\n",
    "    model = XGBClassifier(**Xgb_params)\r\n",
    "    model.fit(X_train,\r\n",
    "              y_train,\r\n",
    "              eval_set=[(X_valid, y_valid)],\r\n",
    "              eval_metric='auc',\r\n",
    "              early_stopping_rounds=EARLY_STOPPING_ROUNDS,\r\n",
    "              verbose=VERBOSE)\r\n",
    "\r\n",
    "    fi_tmp = pd.DataFrame( )\r\n",
    "    fi_tmp['feature'] = X_train.columns\r\n",
    "    fi_tmp['importance'] = model.feature_importances_\r\n",
    "    fi_tmp['fold'] = fold\r\n",
    "    fi_tmp['seed'] = SEED\r\n",
    "    lgb_importances = lgb_importances.append(fi_tmp)\r\n",
    "\r\n",
    "    lgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\r\n",
    "    lgb_pred += model.predict_proba(X_test)[:, -1] / N_SPLITS\r\n",
    "\r\n",
    "    auc = roc_auc_score(y_valid, lgb_oof[val_idx])\r\n",
    "    print(f\"fold {fold} - lgb auc: {auc:.6f}\\n\")\r\n",
    "\r\n",
    "print(f\"oof lgb roc = {roc_auc_score(target, lgb_oof)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\n",
      "================ fold 0 ================\n",
      "========================================\n",
      "[0]\tvalidation_0-auc:0.79960\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('geral': conda)"
  },
  "interpreter": {
   "hash": "4d9061ba3fc48c3e393f5851a44fb8ec3900e3cc009a2196d71166ed16619774"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}